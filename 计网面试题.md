## 一、HTTP与HTTPS有哪些区别？
> HTTPS 要比 HTTP多了secure安全性这个概念，实际上，HTTPS并不是一个新的应用层协议，他其实就是HTTP+TLS/SSL协议
> 组合而成，而安全性的保证是SSL/TSL所做的工作。
> 
**SSL**（安全套接层 Secure Sockets Layer）
**TSL**（传输层安全 Transport Layer Security）
**HTTPS就是身披了一层SSL的HTTP**
![](http://img-repo.poetries.top/images/20210409105003.png)

HTTP与HTTPS的区别？
- HTTP是明文传输协议，HTTPS协议是由SSL+HTTP协议构建的可进行加密传输、身份认证的网络协议，比HTTP安全。
- HTTPS比HTTP更加安全，对搜索引擎更友好，利于SEO。
- HTTPS标准端口443，HTTP标准端口80.
- HTTPS需要用到SSL证书，而HTTP不用。

两点HTTPS主要作用

==1.对数据进行加密，并建立一个信息安全通道，来保证传输过程中的数据安全==

==2.对网站服务器进行真实身份验证==

**HTTPS握手过程**
- 第一步，客户端给出协议版本号、一个客户端生成的随机数（Client random），以及客户端支持的加密算法
- 第二步，服务端确认双方使用的加密方法，并给出数字证书、以及一个服务器生成的随机数
- 第三步，客户端确认数字证书有效，然后生成一个新的随机数（Premaster secret），并使用数字证书中的公钥，加密这个随机数，发给服务端
- 第四步，服务端使用自己的私钥，获取客户端发送来的随机数（即Premaster secret）
- 第五步，客户端和服务端根据约定的加密方法，使用前面的三个随机数，生成“会话密钥”（session kkey），用来机密接下来的整个会话过程


## 二、TCP怎么保证可靠传输？
[TCP滑动窗口和拥塞窗口](https://www.cnblogs.com/diegodu/p/4538897.html)

**TCP协议保证数据传输可靠性的方式主要有**：
（校序重流拥）

*校验和*
发送的数据包的二进制相加然后取反，目的是检测数据在传输中的任何变化。如果收到段的检验和有差错，TCP将丢弃这个报文段和不确认收到此报文段。
*确认应答+序列号*
TCP给发送的每一个包进行编号，接收方对数据包进行排序，把有序数据传送给应用层。
*超时重传*
当TCP发出一个段后，他启动一个定时器，等待目的端确认收到这个报文段。如果不能及时收到一个确认，将重发这个报文段。
*流量控制*
TCP连接的每一方都有固定大小的缓冲空间，TCP的接收端只允许发送端发送接收端缓冲区能接纳的数据。当接收方来不及处理发送方得数据，能提示发送方降低发送的速率，防止包丢失。TCP
使用的流量控制协议是可变大小的滑动窗口协议。
接收方有即时窗口（滑动窗口），随ACK报文发送。
*拥塞控制*
当网络拥塞时，减少数据的发送。
发送方有拥塞窗口，发送数据前比对接收方发过来的即时窗口，取小
慢启动、拥塞避免、拥塞发送、快速恢复

应用数据被分割成TCP认为最适合发送的数据块
TCP的接收端会丢弃重复的数据

### 1.校验和
计算方式：在数据传输的过程中，将发送的数据段都当做一个16位的整数。将这些整数加起来。并且前面的进位不能丢弃，补在后面，最后取反，得到校验和。
发送方：在发送之前计算校验和，并进行校验和的填充。
接收方：收到数据后，对数据以同样的方式进行计算，求出校验和，与发送方的进行对比
![](http://dl2.iteye.com/upload/attachment/0130/5454/6b8138a2-e6d6-3e2b-af10-cac9dabbf38e.png)
tips:如果接收方对比校验和与发送方的不一致，那么数据一定传输有误。但是如果接收方对比校验和与发送方一致，数据不一定传输成功。

### 2.确认应答与序列号
序列号：TCP传输时将每个字节的数据都进行了编号，这就是序列号。
确认应答：TCP传输的过程中，每次接收方接收到数据后，都会对传输方进行确认应答。也就是发送ACK报文。这个ACK报文中带有
对应的确认序列号，告诉发送方，接收到了哪些数据，下一次的数据从哪里发。
![](http://dl2.iteye.com/upload/attachment/0130/5456/ede3ff8a-ad3a-3a4a-bdbb-443a9691cdba.png)
序列号的作用不仅仅是应答的作用，有了序列号能够将接收到的数据根据序列号排序，并且去掉重复序列号的数据。这也是TCP传输可靠性的保证之一。

### 3.超时重传
在进行TCP传输时，由于确认应答与序列号机制，也就是说发送方发送一部分数据后，都会等待接收方发送的ACK报文，并解析ACK报文，判断数据是否传输成功。如果发送方发完数据后，迟迟没有等到接收方的ACK报文，
这该怎么办呢？没有收到报文的原因是什么呢？

首先，发送方没有接收到响应的ACK报文原因可能有两点：
a、数据在传输过程中由于网络原因等直接全体丢包，接收方没有收到
b、接收方接收到了响应数据，但是发送的ACK报文响应却由于网路原因丢包了

TCP在解决这一问题的时候引入了一个新的机制，叫做超时重传机制。简单理解就是发送方在发送完数据后等待一个时间，时间到达没有
接收到ACK报文，那么对刚才发送的数据进行重新发送。如果是刚才的第一个原因，接收方收到二次重发的数据后，便进行ACK应答。如果是
第二个原因，接受方发现接受的数据已经存在（判断的依据就是序列号所以上面说序列号还有去除重复数据的作用），那么直接丢弃，仍旧发送ACK应答。


那么发送方发发送完毕后等待的时间是多少呢？如果这个等待的时间过长，那么会影响TCP传输的整体效率，如果等待时间过短，又会导致频繁的发送重复的包。
如何权衡？

由于TCP传输时保证能够在任何环境下都有一个高性能的通信，因此这个最大超时时间（也就是等待的时间）是动态计算的。

TIPS：超时以500ms为一个单位进行控制，每次判定超时重发的超时时间都是500ms的整数倍。重发一次后，扔未响应，那么等待2`*`500ms的时间后，
再次重传。以一个指数的形式增长。累积到一定的重传次数，TCP就认为网络或者对端出现异常，强制关闭连接。

### 4.连接管理
连接管理就是三次握手与四次挥手的过程。保证可靠地连接，就是保证可靠性的前提。

### 4.1流量控制
接收端在接收到数据后，对其进行处理。如果发送端的发送速度太快，导致接收端的接受缓存区很快的充满了。此时如果发送端仍旧发送数据，
那么接下来发送的数据包都会丢失，继而导致丢包的一系列连锁反应，超时重传等。而TCP根据接收端对数据的处理能力，决定发送端的发送数据，这个机制就是流量控制。

在TCP协议的报头信息当中，有一个16位字段的窗口大小。在介绍这个窗口大小时我们知道，窗口大小的内容实际上是接收端接收数据缓冲区的剩余大小
。这个数字越大，证明接受端接受缓冲区的剩余空间越大，网络的吞吐量越大。接收端会在确认应答发送ACK报文时，将自己的即时窗口大小填入，并跟随ACK报文一起发送过去。
而发送方根据ACK报文里的窗口大小的值的改变进而改变自己的发送速度。如果接收到窗口大小的值为0，那么发送方将停止发送数据。
并定期的向接受端发送窗口探测数据段，让接受端把窗口大小告诉发送端。

![](http://dl2.iteye.com/upload/attachment/0130/5458/645c4330-0cef-3abd-a156-3dded35a6859.png)

TIPS:16位的窗口大小能表示65535个字节(64k)，但是TCP的窗口大小最大并不是64k。在TCP首部中40个字节的选项中还包含了
一个窗口扩大因子M,实际的窗口大小就是16位窗口字段的值左移M位。每移一位，扩大两倍。

### 4.2拥塞控制

TCP传输的过程中，发送端开始发送数据的时候，如果刚开始就发送大量的数据，那么就可能造成一些问题。网络可能在开始的时候
就很拥堵，如果给网络中扔出大量数据，那么这个拥堵就会加剧。拥堵的加剧就会产生大量的丢包，就对大量的超时重传，严重影响传输。

索引TCP引入了慢启动的机制，在开始发送数据时，先发送少量的数据探路。探清当前的网络状态如何，再决定多大的速度进行传输。这时候就引入一个叫做拥塞窗口的概念。
发送刚开始定义拥塞窗口为1，每次收到ACK应答，拥塞窗口加一。在发送数据之前，首先将拥塞窗口与接收端反馈的窗口大小对比，取比较小的值作为实际发送的窗口。

拥塞窗口的增长是指数级别的。慢启动的机制只是在说明在开始的时候发送的少，发送的慢，但是增长的速度是非常快的。为了控制拥塞窗口的增长，不能使用拥塞窗口单纯的加倍，设置一个拥塞窗口的阈值
，当拥塞敞口大小超过阈值是我，不能在按照指数来增长，而是线性的增长。在慢启动开始的时候，慢启动的阈值等于窗口的最大值，一旦造成网络拥塞，
发生超时重传时，慢启动的阈值会为原来的一半(这里的原来指的是发生网络拥塞时拥塞窗口的大小)，同时拥塞窗口重置为1.
![](http://dl2.iteye.com/upload/attachment/0130/5460/954c289d-84e1-35e8-8050-b6f01c35882d.png)

拥塞控制是TCP在传输时尽可能快的将数据传输，并且避免拥塞造成的一系列问题。是可靠性的保证，同时也是维护了传输的高效性。

拥塞控制主要是四个算法：1）慢启动，2）拥塞避免，3）拥塞发生，4)快速恢复。

拥塞避免

当拥塞窗口>=阈值时，就会进入“拥塞避免算法”
这样就可以避免增长过快导致网络拥塞，慢慢的增加调整到网络的最佳值。是一个线性上升的算法。

拥塞发生
当发生超时重传后，阈值会变成拥塞窗口的一半

快速恢复

## 三、TCP与UDP在网络协议的哪一层，他们之间有什么区别？
位于传输层

首先UDP协议是面向无连接的，也就是说不需要在正式传输数据之前先连接起双方。然后UDP协议只是数据报文的搬运工，不保证有序且不丢失的传递到对端，
并且UDP协议也没有任何控制流量的算法，总的来说UDP相较于TCP更加的轻便

### 1.面向无连接的
- 首先UDP是不需要和TCP一样在发送数据前进行三次握手建立连接的，想发数据就开始发送了。
- 并且也只是数据报文的搬运工，不会对数据报文进行任何的拆分和拼接操作
### 2.不可靠性
- 首先不可靠性体现在无连接上，通信都不需要建立连接，想发就发，这样的情况肯定不可靠
- 并且收到什么数据就传递什么数据，并且也不会备份数据，发送数据后也不会关心对方是否已经正确接受到数据了
- 再者网络环境时好时坏，但是UDP没有拥塞控制，一直会为恒定的速度发送数据。即使网络条件不好的情况下可能会导致丢包，但是优点也很明显，在某些实时性要求高的场景就需要UDP而不是TCP

### 3.高效
- 虽然UDP协议不是那么可靠，但是正因为它不是那么的可靠，所以也就没有TCP那么复杂了，需要保证数据不丢失且有序到达。
- 因此UDP的头部开销小，只有八个字节，相比于TCP的至少二十个字节要少得多，在传输数据报文时是很高效的

### 4.传输方式
- UDP不止支持一对一的传输方式，同样支持一对多，多对多，多对一的方式，也就是说UDP提供了单播，多播，广播的功能。

### 5.适合使用的场景
UDP虽然对比TCP有很多缺点，但是正因为这些缺点造就了他的高效的特性，在很多实时性要求高的地方都可以看到UDP的身影。

## 四、从输入 URL 到展现页面的全过程
**1.URL解析**

**2.缓存检查**

**3.DNS解析**

**4.TCP三次握手建立连接**

**5.数据传输**

**6.TCP四次挥手断开连接**

**7.页面渲染**

[](http://interview.poetries.top/days/%E6%AF%8F%E6%97%A5%E4%B8%80%E9%A2%98.html#%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E6%B1%87%E6%80%BB)

## 五、简述TCP三次握手以及四次挥手的流程。为什么需要三次握手以及四次挥手？

**三次握手**

- 第一次握手：客户端发送SYN给客户端，进入SYN_SEND状态
- 第二次握手：服务端收到客户端发送过来的SYN，返回确认号ACK，并一起返回一个SYN，进入SYN_RECV状态
- 第三次握手：客户端收到服务端传送过来的SYN+ACK后，给客户端发送一个ACK。进入ESTABLISED状态。
- 当服务端收到来自客户端的ACK后，也进入ESTABLISHED状态。

**为什么需要三次握手呢？**
原因是TCP提供的是可靠地数据传输
- 考虑一次的问题，首先TCP是面向连接，一次握手肯定建立不了连接，因为客户机给服务器发出请求信息却没有收到回应，客户机是没法判定是否发送成功然后建立连接的。
- 再看两次的情况，假设只有两次握手，当A想建立连接时发送一个SYN，然后等待ACK，结果这个SYN因为网络的问题没有及时到达B，所以A在一段时间内没有收到ACK后，在发送一个SYN，这次B顺利收到，接着A也收到ACK，这是A发送的第一个SYN到达了B，对于B来说这是一个新的连接请求，然后B又为这个连接申请资源，返回ACK，然而这个SYN是个无效的请求，A收到这个SYN的ACK后也并不会理会它，而B却不知道，B会一直为这个连接维持着资源，造成资源的浪费。

**三次握手就没有毛病了？？**
*是的。两次握手的问题在于服务器端不知道一个SYN是否是无效的，而第三次握手机制因为客户端会给服务器回复第二次握手，也意味着服务器会等待客户端的第三次握手，如果第三次握手迟迟不来，客户端会认为这个SYN也是无效的，释放相关资源。*
==但是这时有个问题就是客户端完成第二次握手便认为连接已经建立，而第三次握手可能在传输中丢失，服务端会认为连接是无效的，这时如果Client端向SERVER写数据，Server端将以RST包响应，这时便感知到Server的错误。

**总之，三次握手可以保证任何一次握手失败都是可感知的，不会浪费资源**

:happy:

**四次挥手**
- 第一次挥手：主动方向被动方发送一个FIN报文，之后主动方进入FIN_WAIT1状态
- 第二次挥手：被动方收到主动方发过来的FIN后，会返回一个ACK确认。
- 第三次挥手：当被动方没有传输的数据后，向主动方发送一个FIN报文。
- 第四次挥手：主动方收到被动方发来的FIN报文后，给被动方返回一个确认序列号ACK
- 主动方等待2MSL（最大报文生存时间）后，断开连接

**TIME_WAIT产生的原因以及TIME_WAIT（2MSL）的原因**
- 1.可靠地实现TCP全双工连接的终止

我们必须假象网络是不可靠的，你无法保证你最后发送的ACK报文会一定被对方收到，因此对方处于LAST_ACK状态下的SOCKET可能会因为超时没有收到ACK报文，而重发FIN报文，client必须维护这条连接的状态（保持TIME_WAIT，具体而言，就是这条TCP连接对应的（local_ip,local_port）资源不能被立即释放或重新分配），以便可以重发丢失的ACK，如果主动关闭端不维持TIME_WAIT状态，而是处于CLOSED状态，主动关闭端将会响应一个RST，结果server认为发生错误，导致服务器端不能正常关闭连接。**所以这个TIME_WAIT状态的作用就是用来重发可能丢失的ACK报文。**所以当客户端等待2MSL后，没有收到服务端的ACK报文后，他就知道服务端已收到了ACK报文，所以客户端此时才关闭自己的连接。

- 2.允许老的重复分节在网络中消逝

防止已失效的连接请求报文段出现在本连接中。A在发送完最后一个ACK报文段后，再经过时间2MSL，就可以使本连接持续的时间内所产生的所有报文段都从网络中消失。这样就可以使下一个新的连接中不会出现这种旧的连接请求报文段。

## 六、TCP长连接和短连接有哪些不同的使用场景？


**1.HTTP短连接**
在HTTP/1.0中默认使用的是短连接。也就是说，客户端和服务器每进行一次HTTP操作，就建立一次连接，任务结束就中断连接。

当客户端浏览器访问的某个HTML或者其他类型的Web页中包含有其他的Web资源（如JavaScript文件、图像文件、CSS文件等），每遇到这样一个web资源，浏览器就会重新建立一个HTTP会话。

**2.HTTP长连接**
而从HTTP/1.1起，默认使用长连接，用以保持连接。使用长连接的HTTP协议，会在响应投加入这样的代码：
```COnnection:keep-alive```

在使用长连接的情况下，当一个网页打开完成后，客户端和服务器之间用于传输HTTP数据的TCP连接不会关闭，客户端再次访问这个服务器时，会继续使用这一条已经建立的连接。

keep-alive不会永久保持连接，他有一个保持时间，可以在不同的服务器软件中设定这个时间。实现长连接需要客户端和服务器端都支持长连接。HTTP协议的长连接和短连接，实质上是TCP协议的长连接和短连接。

**3.长连接和短连接的应用场景**

长连接多用于操作频繁，点对点的通讯，而且连接数不能太多的情况。

而像WEB网站的http服务一般都用短连接。因为长连接对于服务器来说会耗费一定的资源。


## 七、HTTP中GET和POST区别
本质上，只是语义上的区别，GET获取资源，POST用于提交资源。

具体差别：
- 从缓存的角度看，GET请求后浏览器会主动缓存，POST请求默认情况下不能
- 从参数角度看，GET请求一般放在URL中，因此不安全，POST请求放在请求体中，相对而言较为安全，但是在抓包的情况下都是一样的，都不安全。
- 从编码角度看，GET请求只能进行URL编码，只能接受ASCII码，而POST支持更多的编码类型且不对数据类型限制
- GET请求幂等，POST请求不幂等，幂等是指发送一次请求和发送多次请求，服务器上资源的状态一致。
- GET请求会一次性发送请求报文，POST请求通常分为两个TCP数据包，首先发header部分，如果服务器响应100（continue），然后发送body部分。

## 八、简述对称与非对称加密的概念

**1.对称加密**
> 加密和解密用同一个密钥的加密方式叫做对称加密。Client客户端和Server服务端共用一套密钥，这样子的加密过程似乎很让人理解，但是随之会产生一些问题
> 
- 问题一：万维网有许许多多的客户端，不可能都用密钥A进行信息加密，这样子很不合理，所以解决办法就是一个客户端使用一个密钥进行加密
- 问题二：既然不同的客户端使用不同的密钥，那么对称密钥的密钥如何传输？那么解决办法只能是一端生成一个密钥，然后通过HTTP传输给另一端，那么这样子又会产生新的问题。
- 问题三：这个传输密钥的过程，有如何保证加密？如果被中间人拦截，密钥也会被获取，那么你会说对密钥再进行加密，那又怎么保存对密钥加密的过程，是加密的过程？

到这里以后，就可以看到对称的加密方式是行不通的，所以就需要非对称的加密方式。

**2.非对称加密**
> 通过上面的分析，对称加密方式行不通，那么我们来梳理一下非对称加密。采用的算法是RSA，所以在一些文章中也会看见传统RSA握手，基于现在TLS1.2，所以接下来梳理的是TLS/1.2握手过程。
> 
非对称加密中，我们需要明确的是：
- 有一对密钥，公钥和私钥。
- 公钥加密的内容只有私钥才能解开，这里说的私钥都可以解开，指的是一对密钥。
- 公钥可以发送给所有的客户端，私钥只保存在服务器端

**3.主要工作流程**

梳理起来，可以把TLS1.2握手过程分为主要的五步：
![](http://img-repo.poetries.top/images/20210409105413.png)
- 步骤一：Client发起一个HTTPS请求，连接443端口。这个过程可以理解成是请求公钥的过程。
- 步骤二：Server端收到请求后，通过第三方机构私钥的加密，会把数字证书（也可认为是公钥证书）发送给Client。
- 步骤三：
    - 浏览器安装后会自动带一些权威第三方机构公钥，使用匹配的公钥对数字签名进行解密。
    - 根据签名生成的规则对网站信息进行本地签名生成，然后两者进行对比。
    - 通过比对两者签名，匹配则说明认证通过，不匹配则说明获取整数失败

- 步骤四：在安全拿到服务器公钥后，客户端Client随机生成一个对称密钥，使用服务器公钥（证书的公钥）加密这个对称密钥，发给Server端。
- 步骤五：Server通过自己的私钥，对信息解密，至此得到了对称密钥，此时两者都拥有了相同的对称密钥

接下来就可以通过该对称密钥对传输的信息加密/解密。举个栗子来说：

- Client用户使用该对称密钥加密“明文内容B”，发送给Server
- Server使用该对称密钥进行解密消息，得到明文内容B

这里有一个问题需要考虑的是，假如公钥被中间人拿到篡改怎么办呢？
![](http://img-repo.poetries.top/images/20210409105827.png)
客户端拿到的公钥是假的，解决办法是什么呢？
**3.第三方认证**
客户端无法识别传回公钥是中间人的，还是服务器的，这是问题的根本，我们是不是可以通过某种规范可以让客户端和服务器都遵循某种约定呢？那就是通过第三方认证的方式

在HTTPS中，通过**证书+数字签名**来解决这个问题。
![](http://img-repo.poetries.top/images/20210409105910.png)
这里唯一不同的是，假设对网站信息加密的算法是MD5，通过MD5加密后，然后通过第三方机构的私钥再次对其加密，生成数字签名。

这样子的话，数字证书包含有两个特别重要的信息：**某网站公钥+数字签名**
> 我们再次假设中间人截取到服务器的公钥后，会替换成自己的公钥，因为有数字签名的存在，这样子客户端验证发现数字签名不匹配，这样子客户端验证发现数字签名不匹配，这样子就防止中间人替换公钥的问题。
> 

那么客户端是如何去对比两者的数字签名的呢》

- 浏览器会去安装一些权威的第三方认证机构的公钥，比如VeriSign、Symantec以及GlobalSign等等。
- 验证数字签名的时候，会直接从本地拿到相应的第三方的公钥，对私钥加密后的数字签名进行解密得到真正的签名。
- 然后客户端利用签名生成的规则进行签名生成，看两个签名是否匹配，如果匹配认证通过，不匹配则获取证书失败。

**4.数字签名的作用**
> 数字签名：将网站的信息，通过特定的算法加密，比如MD5，加密之后，再通过服务器的私钥进行加密，形成加密后的数字签名。
> 
第三方认证机构是一个公开的平台，中间人可以去获取。

如果没有数字签名的话，这样子就会有下面情况
![](http://img-repo.poetries.top/images/20210409110016.png)
从上面我们知道如果只是对网站信息进行第三方机构私钥加密的话，还是会受到欺骗。

因为没有认证，所以中间人也向第三方认证机构进行申请，然后拦截后把所有的信息都替换成自己的，客户端仍然可以解密，并且无法判断这是服务器还是中间人的，最后造成数据泄露。



## 九、简述常见的HTTP状态码的含义（301，304，401，403）
## 十、Cookie与Session的关系和区别是什么？
- session：是一个抽象概念，开发者为了实现中断和继续等操作，将`user-agent`和`server`之间一对一的交互，抽象为“会话”，进而衍生出“会话状态”，也就是`session`的概念。
- `cookie`：它是一个实际存在的东西，`http`协议中定义在`header`中的字段，可以认为是`session`的一种后端无状态的实现。

> 现在我们常说的session，是为了绕开cookie的各种限制，通常借助cookie本身和后端存储实现的，一种更高级的会话状态的实现
> 
session的常见实现需要借助cookie来发送sessionID


## 十二、简述DDOS攻击原理，如何防范它？
## 十三、简述HTTP1.0，1.1，2.0的主要区别

- HTTP0.9：1991年，原型版本，功能简陋，只有一个命令GET，只支持纯文本内容，该版本已过时
- HTTP1.0：
    - 任何格式的内容都可以发送，这使得互联网不仅可以传输文字，还能传输图像、视频、二进制等文件
    - 除了GET命令外，还引入了POST命令和HEAD命令
    - HTTP请求和回应的格式改变，除了数据部分，每次通信都包括头信息（HTTP HEADER），用来描述一些元数据
    - 只使用header中的`If-Modified-Since`和`Expires`作为缓存失效的标准。
    - 不支持断点续传，也就是说，每次都会传送全部的页面和数据。
    - 通常每次计算机只能绑定一个IP，所以请求消息中的URL并没有传递主机名
- HTTP1.1：HTTP1.1是目前最为主流的http协议版本，自1999年发布至今，仍是主流的HTTP协议版本
    - 引入了持久连接，即TCP连接默认不关闭，可以被多个请求复用，不用声明Connection:keep-alive。长连接的连接时长可以通过请求头中的`keep-alive`来设置。
    - 引入了管道机制，即在同一个TCP连接里，客户端可以同时发送多个请求，进一步改进了HTTP协议的效率。
    - HTTP1.1中新增加了E-tag，If-Unmodified-Since，If-Match，If-None-Match等缓存控制标头来控制缓存失效
    - 支持断点续传，通过请求投中的Range来实现
    - 使用了虚拟网络，在一台物理服务器上可以存在多个虚拟主机，并且他们共享一个IP地址
    - 新增方法：PUT、PATCH、OPTIONS、DELETE

**http1.x版本问题**
- 在传输数据过程中，所有内容都是明文，客户端和服务端都无法验证对方的身份，无法保证数据的安全性
- HTTP/1.1版本默认允许复用TCP连接，但是在同一个TCP连接里，所有数据通信是按次序进行的，服务器通常在处理完一个请求后，才会继续去处理下一个，这样子就会造成队头阻塞
- HTTP/1.x版本支持keep-alive，用此方案来弥补创建多次连接产生的延迟，但是同样会给服务器带来压力，并且的话，对于单文件被不断请求的服务，keep-alive会极大影响性能，因为它在文件被请求之后还保持了不必要的连接很长时间。

**HTTP2.0**
- 二进制分帧：这是一次彻底的二进制协议，头信息和数据体都是二进制，并且统称“帧”：头信息帧和数据帧
- 头部压缩：HTTP1.1版本会出现User-Agent\Cookie\Accept\Server\Range等字段可能会占用几百甚至几千字节，而Body却经常只有几十字节，所以导致头部偏重。HTTP2.0使用HPACK算法进行压缩。
- 多路复用：复用TCP连接，在一个连接里，客户端和浏览器都可以同时发送多个请求或回应，且不用按顺序一一对应，这样子解决了队头阻塞的问题
- 服务器推送：允许服务器未经请求，主动向客户端发送资源，即服务器推送。
- 请求优先级：可以设置数据帧的优先级，让服务器先处理重要的资源，优化用户体验。
## 十四、什么是ARP协议？简述其使用场景
## 十五、简述在四层和七层网络协议中负载均衡的原理

[四层、七层负载均衡的区别](https://www.jianshu.com/p/fa937b8e6712)
1.所谓四层就是基于IP+端口的负载均衡
2.七层就是基于URL等应用层信息的负载均衡

同理，还有基于MAC地址的二层负载均衡和基于IP地址的三层负载均衡。换句话说，二层负载均衡会通过一个虚拟MAC地址接收请求，然后再分配到真实的MAC地址；三层负载均衡会通过一个虚拟IP地址接收请求，然后再分配到真实的IP地址；四层通过虚拟IP+端口接收请求，然后再分配到真实的服务器；七层通过虚拟的URL或主机名接收请求，然后再分配到真实的服务器。

所谓的四到七层负载均衡，就是在对后台的服务器进行负载均衡时，依据四层的信息或者七层的信息来决定怎么转发流量。

比如四层的负载均衡，就是通过发布三层的IP地址，然后再加上四层的端口号，来决定哪些流量需要做负载均衡，对需要处理的流量进行NAT处理，转发至后台服务器，并记录下这个TCP或者UDP的流量是由哪台服务器处理的，后续的这个连接的所有流量都同样转发到同一台服务器处理。

七层的负载均衡，就是在四层的基础上（**没有四层是绝对不可能有七层的**），再考虑应用层的特征，比如一个WeB服务器的负载均衡，除了根据VIP加80端口辨别是否需要处理的流量，还可以根据七层的URL、浏览器类别，语言来决定是否要进行负载均衡。举个栗子，如果你的web服务器分成两组，一组是中文语言的，一组是英文语言的，那么七层负载均衡就可以当用户来访问你的域名时，自动辨别用户语言，然后选择对应的语言服务器组进行负载均衡处理。

负载均衡器通常称为四层交换机或七层交换机。四层交换机主要分析IP层及TCP/UDP层，实现四层流量负载均衡。七层交换机除了支持四层负载均衡以外，还有分析应用层的信息，如HTTP协议、URL或Cookie信息。

负载均衡分为L4 switch（四层交换），即在OSI第四层工作，就是TCP层。此种Load Balance不理解应用协议（如HTTP/FTP/MYSQL等）

另一种叫L7 switch（七层交换），OSI的最高层，应用层。此时，该load balance能理解应用协议


**区别**
1.技术原理上，所谓四层负载均衡，也就是主要通过报文中的目标地址和端口，再加上负载均衡设备设置的服务器选择方式，决定最终选择的内部服务器。

以常件的TCP为例，负载均衡设备在接收到第一个来自客户端的SYN请求时，即通过上述方式选择一个最佳的服务器，并对报文中的目标IP地址进行修改（改为后端服务器IP），直接转发给该服务器。TCP的连接建立，即三次握手是客户端和服务器直接建立的，负载均衡是起到一个类似路由器的转发动作。在某些部署情况下，为保证服务器回包可以正确返回给负载均衡设备，在转发豹纹的同时可能还会对报文原来的源地址进行修改。
![](https://upload-images.jianshu.io/upload_images/1787733-614f0b870366e3cc.png?imageMogr2/auto-orient/strip|imageView2/2/w/426/format/webp)

所谓七层负载均衡，也称为“内容交换”，也就是主要通过报文中的真正有意义的应用层内容，再加上负载均衡设备设置的服务器选择方式，决定最终选择的内部服务器。

以常见的TCP为例，负载均衡设备如果要根据真正的应用层内容再选择服务器，只能先代理最终的服务器和客户端建立连接（三次握手）后，才可能接收到客户端发送的真正应用层内容的报文，然后再根据该报文中的特定字段，再加上负载均衡设备设置的服务器选择方式，决定选择最终的内部服务器。均衡设备在这种情况下，更类似于一个代理服务器。负载均衡和前端的客户端以及后端的服务器会分别建立TCP连接。所以从这个技术原理上来看，七层负载均衡明显的对负载均衡设备的要求更高，处理七层的能力也必然会低于四层模式的部署方式。

2.应用场景

七层应用负载的好处，是使得整个网络更智能化。例如访问一个网站的用户流量，可以通过七层的方式，将对图片类的请求转发到特定的图片服务器并可以使用缓存技术；将对文字类的请求可以转发到特定的文字服务器并可以使用压缩技术。当然这只是七层应用的一个小案例，从技术原理上来，这种方式可以对客户端的请求和服务器的响应进行任何意义上的修改，极大地提升了应用系统在网络层的灵活性。很多在后台，例如Nginx或者Apache上部署的功能可以前移到负载均衡设备上，例如客户请求的重写，服务器响应中的关键字过滤或者内容插入等功能。

另一个常常被提到的功能就是安全性。网络中最常见的SYN Flood攻击，即黑客控制众多源客户端，使用虚假IP地址对同一目标发送SYN攻击，通常这种攻击会大量发送SYN报文，耗尽服务器上的相关资源，以达到Denial of Service（DOS）的目的。从技术原理上也可以看出，四层模式下这些SYN攻击都会被转到后端的服务器上；而七层模式下这些SYN攻击自然在负载均衡设备上就截止，不会影响后台服务器的正常运营，另外负载均衡设备可以在七层层面设定多中层略，过滤特定报文，例如SQL Injection（SQL注入）等应用层的特定攻击手段，从应用层面进一步提高系统整体安全。

现在的七层负载均衡，主要还是着重应用HTTP协议，所以其应用范围主要是众多的网站或者内部信息平台等基于B/S开发的系统。4层负载均衡则对应其他TCP应用，例如基于C/S开发的ERP等系统。

## 十六、什么是TCP粘包和拆包？
## 十七、RESTFUL是什么？RESTFUL请求的URL有什么特点？
## 十八、简述HTTP报文头部的组成结构



